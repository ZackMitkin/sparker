{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import sparker\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profile_id': 0, 'attributes': [{'key': 'company_name', 'value': 'Meezzy'}, {'key': 'createddate', 'value': '01-14-2018'}, {'key': 'deleteddate', 'value': ''}, {'key': 'isdeleted', 'value': 'FALSE'}], 'original_id': '0959a851-bd0d-4fb6-8a89-052ac4f28279', 'source_id': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[99]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "customers = spark.read.json(\"../datasets/clean/customers/accounts.jsonl\")\n",
    "customer_profiles = sparker.DataFrameWrapper.load_profiles(\n",
    "    customers, real_id_field=\"id\", source_id=1, ignored_columns=[\"lastmodifiedid\", \"cleanstatus\", \"engagement_level\", \"industry\", \"payment_recieved\", \"ownerid\", \"site\", \"total_products_used\"])\n",
    "\n",
    "separator_id = customer_profiles.map(lambda profile: profile.profile_id).max()\n",
    "separator_ids = [separator_id]\n",
    "\n",
    "print(customer_profiles.take(1)[0])\n",
    "separator_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = spark.read.json(\"../datasets/clean/interactions/calls.jsonl\")\n",
    "interactions = sparker.DataFrameWrapper.load_profiles(\n",
    "    interactions, start_id_from=separator_id+1, real_id_field=\"id\", source_id=2)\n",
    "# Max profile id\n",
    "max_profile_id = interactions.map(lambda profile: profile.profile_id).max()\n",
    "max_profile_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = customer_profiles.union(interactions)\n",
    "profiles.toDF().write.json(\"profiles\", \"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cluster_id': 0, 'keys': ['2_is_public', '1_isdeleted'], 'entropy': 0.8800807124389624},\n",
       " {'cluster_id': 1, 'keys': ['2_updated_at', '1_deleteddate'], 'entropy': 3.688587246318698},\n",
       " {'cluster_id': 2, 'keys': ['2_created_at', '1_createddate'], 'entropy': 4.656398012907379},\n",
       " {'cluster_id': 3, 'keys': ['2_content', '1_company_name', '2_priority', '2_type', '2_status', '2_customer_id'], 'entropy': 14.381599915540582}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = sparker.AttributeClustering.cluster_similar_attributes(profiles,\n",
    "                                                                  num_hashes=128,\n",
    "                                                                  target_threshold=0.5,\n",
    "                                                                  compute_entropy=True)\n",
    "                                                                  #keys_to_exclude=[\"contact_first_name\", \"photourl\", \"contact_last_name\", \"account_executive\", \"onboarding_complete\"])\n",
    "clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT 1478\n",
      "Number of blocks 45\n"
     ]
    }
   ],
   "source": [
    "blocks = sparker.Blocking.create_blocks_clusters(profiles, clusters, separator_ids)\n",
    "print(\"Number of blocks\",blocks.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_purged = sparker.BlockPurging.block_purging(blocks, 1.005)\n",
    "sc = spark.sparkContext\n",
    "# Performs the cleaning\n",
    "(profile_blocks, profile_blocks_filtered,\n",
    " blocks_after_filtering) = sparker.BlockFiltering.block_filtering_quick(blocks_purged, 0.8, separator_ids)\n",
    "\n",
    "block_index_map = blocks_after_filtering.map(\n",
    "    lambda b: (b.block_id, b.profiles)).collectAsMap()\n",
    "block_index = sc.broadcast(block_index_map)\n",
    "\n",
    "block_entropies = sc.broadcast(blocks.map(\n",
    "    lambda b: (b.block_id, b.entropy)).collectAsMap())\n",
    "\n",
    "# This is only needed for certain weight measures\n",
    "profile_blocks_size_index = sc.broadcast(profile_blocks_filtered.map(\n",
    "    lambda pb: (pb.profile_id, len(pb.blocks))).collectAsMap())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.0\n",
      "Number of comparisons 2963\n"
     ]
    }
   ],
   "source": [
    "results = sparker.WNP.wnp(\n",
    "                          profile_blocks_filtered,\n",
    "                          block_index,\n",
    "                          max_profile_id,\n",
    "                          separator_ids,\n",
    "                          weight_type=sparker.WeightTypes.CHI_SQUARE,\n",
    "                          profile_blocks_size_index=profile_blocks_size_index,\n",
    "                          use_entropy=True,\n",
    "                          blocks_entropies=block_entropies,\n",
    "                          chi2divider=2.0\n",
    "                         )\n",
    "num_edges = results.map(lambda x: x[0]).sum()\n",
    "num_matches = results.map(lambda x: x[1]).sum()\n",
    "print(\"Precision\", num_matches/num_edges)\n",
    "print(\"Number of comparisons\",num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "edges = results.flatMap(lambda x: x[2])\n",
    "\n",
    "plot = nx.Graph()\n",
    "for row in edges.take(20000):\n",
    "    plot.add_edge(row[0], row[1], weight=row[2].item())\n",
    "\n",
    "nx.write_graphml(plot, \"edge.graphml\")\n",
    "\n",
    "edges_df: DataFrame = edges.map(\n",
    "    lambda x: Row(dst=x[0], src=x[1], weight=x[2].item())).toDF().cache()\n",
    "\n",
    "edges_df.write.json(\"edges\", \"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
